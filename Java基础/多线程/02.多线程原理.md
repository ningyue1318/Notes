## Java内存模型(JMM)

### Java并发解决的三个问题

- **可见性**-保证指令不会受cpu缓存的影响

```java
//加锁的时候会导致可见性，println是加锁的，所以while里面加了输出就会同步，
//用来解释可见性的问题，
   static volatile boolean run = true;

    public static void main(String[] args) throws InterruptedException {
        Thread t =new Thread(()->{
            while(run){
            }
        });
        t.start();

        Thread.sleep(1000);
        System.out.println("停止");
        run = false;
    }
```

<img src="resources/JMM示意图.PNG" style="zoom:50%;" />

如上图所示，为JMM内存模型，每一个线程都有自己的工作内存，这里保存了变量的副本，所有的修改操作都是在工作内存中完成后，刷新到主内存，内存之间的通信也是通过主内存进行的。由于上面的原因导致了可见性的问题。

- **有序性**-保证指令不会受cpu指令并行优化的影响

```java
/*
可能出现的情况
情况1：线程1 先执行，这时 ready = false，所以进入 else 分支结果为 1
情况2：线程2 先执行 num = 2，但没来得及执行 ready = true，线程1 执行，还是进入 else 分支，结果为1
情况3：线程2 执行到 ready = true，线程1 执行，这回进入 if 分支，结果为 4（因为 num 已经执行过了）
情况4：线程2 执行 ready = true，切换到线程1，进入 if 分支，相加为 0，再切回线程2 执行 num = 2，出现了指令重排序
*/

int num = 0;
boolean ready = false;
// 线程1 执行此方法
public void actor1(I_Result r) {
     if(ready) {
         r.r1 = num + num;
     } else {
    	 r.r1 = 1;
     }
}
// 线程2 执行此方法
public void actor2(I_Result r) { 
     num = 2;
     ready = true; 
}
```

![](resources\实验结果.PNG)

可以看到0的结果还是出现了，尽管出现的情况不多。

重排序分为下面几种，为了避免各种重排序，需要加入内存屏障。

<img src="resources\重排序种类.PNG" style="zoom:50%;" />

- **原子性**-保证指令不会受到线程上下文切换的影响

  下面是一个普通的i++操作。可以看到分了4条指令，必须保证在这四条指令执行的期间不能发生线程切换，否则就会报错。

![](resources\原子性示意图.PNG)

### Happen-Before原则：

Happen-Before原则，说明的是前一个操作对后一个操作是可见的。这个原则就是方便程序员理解编译器的重排序规则，更好的理解可见性

重排序的原则：

1. 重排序不能改变如下的数据依赖

<img src="resources\数据依赖.PNG" style="zoom:50%;" />

2. 不管怎么重排序，不能改变程序的执行结果，要像串行一样，即as-if-serial
3. 在临界区内可以重排序，但不能让临界区内的代码逃逸出临界区。synchronized包裹的程序可以重排序，但是不能有里面的变量可以在外面访问。

Happen-Before原则

1.  按照程序顺序，前面的操作 Happens-Before 于后续的任意操作。
2. 一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile变量的读操作。
3. 这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。
4. 这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。
5. 它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。
6. 它是指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作

## volatile原理

volatile适用一个线程写多个线程读取的情况

有volatile变量修饰的代码，反汇编之后会加上lock前缀，这个前缀会产生两个效果。

- Lock前缀指令会引起处理器缓存写回到内存
- 一个处理器的缓存写回到内存会导致其他处理器的缓存无效。

volatile更底层的实现是内存屏障

- 对volatile的写指令会插入写屏障，写屏障保证在该屏障之前的，对共享变量的改动，都同步到主存当中。
- 对volatile的读指令会插入读屏障，读屏障保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据

volatile禁止重排序的种类：

<img src="resources\volatile重排序.PNG" style="zoom:50%;" />

- 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile写之前的操作不会被编译器重排序到volatile写之后。 

- 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile读之后的操作不会被编译器重排序到volatile读之前。 

- 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。

为了实现上面的语义，需要以下重排序操作的配合。

<img src="resources\内存屏障类型.PNG" style="zoom:50%;" />

- 在每个volatile写操作的前面插入一个StoreStore屏障。 

- 在每个volatile写操作的后面插入一个StoreLoad屏障。 

- 在每个volatile读操作的后面插入一个LoadLoad屏障。 

- 在每个volatile读操作的后面插入一个LoadStore屏障。

  下面的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序

  <img src="resources\volatile读插入的屏障.PNG" style="zoom:50%;" />

下面的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任 意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。volatile写后面的StoreLoad屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序

<img src="resources\volatile写插入的屏障.PNG" style="zoom:50%;" />

## synchronized实现原理

### Java对象头

对象在内存中分为三块区域：

- 对象头

  1. MarkWord(标记字段)，默认存储对象的HashCode，分代年龄和锁标志位信息。里面存储的数据会随着锁标志位的变化而变化。
  2. Klass Point(类型指针)，对象指向它的类元数据指针，通过这个指针确定对象是那个类的实例

- 实例数据

  存放类的数据信息，父类信息

- 对齐填充

  虚拟机要求对象起始地址必须是8字节的整倍数，填充数据不是必须存在的，仅仅是为了字节对齐

32位虚拟机中对象头的组成

![](resources/32位虚拟机结构.PNG)

32位虚拟机中对象头的组成
![](resources/32位虚拟机markword结构.PNG)
64位虚拟机中对象头的组成

![](resources/64位虚拟机markword结构.PNG)

**biased_lock**：对象是否启用偏向锁标记，只占1个二进制位。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。
 **age**：4位的Java对象年龄。在GC中，如果对象在Survivor区复制一次，年龄增加1。当对象达到设定的阈值时，将会晋升到老年代。默认情况下，并行GC的年龄阈值为15，并发GC的年龄阈值为6。由于age只有4位，所以最大值为15，这就是`-XX:MaxTenuringThreshold`选项最大值为15的原因。
 **identity_hashcode**：25位的对象标识Hash码，采用延迟加载技术。调用方法`System.identityHashCode()`计算，并会将结果写到该对象头中。当对象被锁定时，该值会移动到管程Monitor中。
 **thread**：持有偏向锁的线程ID。
 **epoch**：偏向时间戳。
 **ptr_to_lock_record**：指向栈中锁记录的指针。
 **ptr_to_heavyweight_monitor**：指向管程Monitor的指针。

### 管程

管程，对应的英文是Monitor，指管理共享变量以及对共享变量操作的过程，让他们支持并发。在管程的发展历史上分别有三种不同的管程模型，分别是Hasen模型，Hoare模型，MESA模型。

并发领域要解决的问题：

- 互斥：即同一时刻只允许一个线程访问共享资源。
- 同步：即线程之间如何通信，协作。

管程的解决方法：

- 互斥：将共享变量及其对共享变量的操作统一封装起来。

- 同步：利用条件变量和条件变量等待队列。

  ![](resources/MESA管程模型.PNG)

在管程模型里，共享变量和对共享变量的操作是被封装起来的，最外层的框就是封装的意思。每一个条件变量都对应一个等待队列。例如，现在线程T1执行阻塞队列的出队操作，如果队列是空的就到条件变量对应的等待队列里面等。如果T2执行阻塞队列的入队操作。队列满了，进入对应条件变量的等待队列里面等。

```java
//阻塞队列的实现上面的思想
public class BlockedQueue<T>{
  final Lock lock =
    new ReentrantLock();
  // 条件变量：队列不满  
  final Condition notFull =
    lock.newCondition();
  // 条件变量：队列不空  
  final Condition notEmpty =
    lock.newCondition();

  // 入队
  void enq(T x) {
    lock.lock();
    try {
      while (队列已满){
        // 等待队列不满 
        notFull.await();
      }  
      // 省略入队操作...
      //入队后,通知可出队
      notEmpty.signal();
    }finally {
      lock.unlock();
    }
  }
  // 出队
  void deq(){
    lock.lock();
    try {
      while (队列已空){
        // 等待队列不空
        notEmpty.await();
      }
      // 省略出队操作...
      //出队后，通知可入队
      notFull.signal();
    }finally {
      lock.unlock();
    }  
  }
}
```

1. Hasen 模型里面，要求 notify() 放在代码的最后，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。
2. Hoare 模型里面，T2 通知完 T1 后，T2 阻塞，T1 马上执行；等 T1 执行完，再唤醒 T2，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。
3. MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。

下面是Java中管程的实现
![](resources/Java中管程的实现.PNG)

### 各种锁

锁的升级顺序如下
```mermaid
graph LR
A[无锁] -->B[偏向锁] --> C[轻量级锁] -->D[重量级锁]
```
- 偏向锁：解决同一个线程多次获得锁时候的代价。
- 轻量级锁：如果一个对象虽然有多线程访问，但多线程访问的时间是错开的（也就是没有竞争），那可以使用轻量级锁来优化。轻量级锁对使用者是透明的，即语法依然是synchronized

#### 偏向锁

在第一次进入的时候，需要CAS将线程ID放在对象的MarkWord头，之后发现线程ID是自己的就表示没有竞争，不需要重新CAS。只要不发生竞争，这个对象就归线程所有。

- 调用hashcode()方法，会导致偏向锁被禁用，直接调用轻量级锁。因为偏向锁的Markword中没有存储hashcode的位置，轻量级锁会在锁记录中记录hashCode，重量级锁会在Monitor中记录hashCode。

- 当有其他线程调用偏向锁对象的时候，会升级成轻量级锁。注意，是在当前线程执行完synchronized方法之后调用，否则就会升级成重量级锁。

- 调用wait，notify也会撤销偏向锁，因为只有重量级锁有这两个方法。

#### 轻量级锁

加锁过程：

1. 创建锁记录对象(LockRecord)，每个线程的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的Mark Word。

    <img src="resources/轻量级锁1.PNG" style="zoom:50%;" />

2. 让锁记录中的Object reference指向锁对象，并尝试用cas替换Object的Mark Word，将MarkWord存入锁记录（就是这里存储了HashCode）。

    <img src="resources/轻量级锁2.PNG" style="zoom:50%;" />

3. 如果cas替换成功，对象头中存储了锁记录的地址和状态00，表示由该线程给对象加锁。

    <img src="resources/轻量级锁3.PNG" style="zoom:50%;" />

4. 如果cas失败，有两种情况

    (1)如果是其他线程持有了Object的轻量级锁，表名有竞争，进入锁膨胀过程。

    (2)如果是自己执行了synchronized锁充入，则在添加一条LockRecord作为重入的计数。

    <img src="resources/轻量级锁4.PNG" style="zoom:50%;" />

锁膨胀：如果别的线程CAS的时候，发现已经有线程加了偏向锁1，自己会申请Monitor锁，让Object指向重量级锁地址，同时自己进入Monitor的EntryList阻塞。

自旋转优化：如果在争取的时候发现阻塞，可以先自旋尝试获取锁，失败10次后进入锁膨胀。

#### 重量级锁

Java中Monitor的详细情况

加入synchonized之后，在子字节码中会出现MonitorEnter和MonitorExit两条指令。

<img src="resources/Java中Monitor详细.PNG" style="zoom:50%;" />

## 线程池

<img src="resources\Executor框架.PNG" style="zoom: 67%;" />

Executor框架分为三个大部分，所有实现了Runnable借口和Future接口的类都能被ThreadPoolExecutor和ScheduledThreadPoolExecutor执行：

- 任务：包括被执行任务需要实现的接口：Runnable和Callable接口。

- 任务的执行，ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务，ScheduledThreadPoolExecutor是一个延迟后运行的命令。

- 异步计算的结果，Future接口和FutureTask类。

Executor框架执行的示意图如下：主线程创建Runnable或者Callable接口的任务对象，并且提交到ExecutorService执行，执行后如果有结果通过Future对象返回。

  <img src="resources\Executor框架执行图.PNG" style="zoom:67%;" />

  

  

```java
 public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
```

- corePoolSize核心线程数目（最多保留线程数）
- maximumPoolSize最大线程数目
- keepAliveTime生存时间-针对急救线程
- unit时间单位-针对就即线程
- workQueue阻塞队列
- threadFactory线程工厂-可以为线程创建时起个好名字
- handler拒绝策略

**线程池的工作流程**：

1. 线程池开始的时候没有线程，当任务被提交给线程后，线程池会创建一个新线程来执行任务。

2. 当线程数达到了corePoolSize且并没有线程空闲时间，这时在加入任务，会被添加到workQueue队列排队，直到有空闲的线程。

3. 如果队列选择了有界队列，当任务超过了队列大小时，会创建maximumPoolSize-corePoolSize数目的线程来救急。

4. 当线程达到maximumPoolSize的时候，仍然有任务加入，会执行拒绝策略。

   - AbortPolicy让调用者抛出RejectedExecutionException异常，这是默认策略

   - CallerRunsPolicy让调用者运行任务

   - DiscardPolicy放弃本次任务

   - DiscardPolicy放弃队列中最早的任务，取而代之。

 ![](resources\拒绝策略.PNG)